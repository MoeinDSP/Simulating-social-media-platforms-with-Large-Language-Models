{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 0. Setup"],"metadata":{"id":"eUCDwR7OcVeG"}},{"cell_type":"markdown","source":["Imports core libraries for graph modeling, visualization, data handling, and API interaction."],"metadata":{"id":"rpQoASsTmJRf"}},{"cell_type":"code","source":["import networkx as nx\n","import matplotlib.pyplot as plt\n","import sys\n","import json\n","import os\n","\n","from datetime import datetime\n","from itertools import combinations\n","from openai import OpenAI\n","from collections import defaultdict\n","from pprint import pprint\n","from itertools import combinations\n","from google.colab import drive"],"metadata":{"id":"EnoAUXtXAppi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Mount google drive to store experiments persistently:"],"metadata":{"id":"ho0y41LXldcj"}},{"cell_type":"code","source":["drive.mount('/content/drive')\n","\n","path = 'MSc AI Polimi/Multidisciplinary Project/Implementation/Experiments'\n","\n","os.chdir(f'/content/drive/MyDrive/{path}')\n","os.getcwd()"],"metadata":{"id":"N-Qk1IDzlY-7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**API Configuration and Client Setup**  \n","Defines model, endpoint, and client configurations for managing OpenAI API access.\n","\n","**Attributes:**\n","\n","- `models`: Maps model names to their identifiers.\n","- `base_urls`: Stores base API endpoints.\n","- `clients_details`: A list of dictionaries, each containing:\n","  - `base_url`: The endpoint for API access.\n","  - `api_key`: A unique API key used for authenticating requests.\n","\n","**clients**:  \n","A list of initialized `OpenAI` client objects, each created using the respective API key and base URL from `clients_details`.  \n","Useful for distributing requests across multiple keys to avoid rate limits."],"metadata":{"id":"4_FwoOvlmNke"}},{"cell_type":"code","source":["models = {\n","    'DeepSeek-V3-0324': 'deepseek/deepseek-chat-v3-0324:free'\n","}\n","\n","base_urls = {\n","    'OpenRouter': 'https://openrouter.ai/api/v1',\n","}\n","\n","clients_details = [\n","    {\n","        'base_url': base_urls['OpenRouter'],\n","        'api_key': \"\"\n","    },\n","    {\n","        'base_url': base_urls['OpenRouter'],\n","        'api_key': \"\"\n","    },\n","\n","]\n","\n","clients = [\n","    OpenAI(\n","        base_url=client['base_url'],\n","        api_key=client['api_key']\n","    ) for client in clients_details\n","]"],"metadata":{"id":"zA1W1r1E2hQw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Client Rotation Logic**  \n","Handles active API client selection and rotation to avoid request limit issues.\n","\n","**Attributes:**\n","\n","- `current_client_idx`: Index of the currently active client.\n","- `current_client`: The active `OpenAI` client object used for API calls.\n","\n","**Functions:**\n","\n","- `update_current_client()`:  \n","  Increments the `current_client_idx` to point to the next client in the list (with wrap-around).  \n","  Updates `current_client` accordingly to maintain uninterrupted API access."],"metadata":{"id":"Hil4ztSNlDPt"}},{"cell_type":"code","source":["current_client_idx = 0\n","current_client = clients[current_client_idx]\n","\n","def update_current_client():\n","  global current_client_idx, current_client\n","  current_client_idx = (current_client_idx + 1) % len(clients)\n","  current_client = clients[current_client_idx]"],"metadata":{"id":"UlR91rcvwVXw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1. Social Network Creation"],"metadata":{"id":"bXdHREqh5eHH"}},{"cell_type":"markdown","source":["**Agent** Class  \n","Represents an individual entity with a defined persona (e.g., name, traits, background).\n","\n","**Attributes:**\n","\n","- `persona`: A dictionary containing descriptive attributes of the agent (e.g., `{\"Name\": \"Alice\", \"Role\": \"Teacher\"}`)."],"metadata":{"id":"cyI3ldq9-x0i"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"IK-FkKpq2zad"},"outputs":[],"source":["class Agent:\n","  def __init__(self, persona: dict):\n","    self.persona = persona"]},{"cell_type":"markdown","source":["**SocialNetwork** Class  \n","Represents a network of agents using a graph structure. Enables group formation, visualization, and interaction modeling.\n","\n","**Attributes:**\n","\n","- `agents`: List of `Agent` instances.\n","- `network`: Undirected graph (using NetworkX) with agents as nodes.\n","- `groups`: List of created groups.\n","\n","**Methods:**\n","\n","- `__create_network()`: Initializes a graph with nodes for each agent.\n","- `draw_network()`: Displays the network graph with labels.\n","- `create_group(members, model)`:\n","  - Connects selected agents.\n","  - Creates a `Group` with those agents and the specified model.\n","  - Adds it to the `groups` list."],"metadata":{"id":"yXyRSWDDn2UV"}},{"cell_type":"code","source":["class SocialNetwork:\n","  def __init__(self, agents: list[Agent]):\n","    self.agents = agents\n","    self.network = self.__create_network()\n","    self.groups = []\n","\n","  def __create_network(self):\n","    network = nx.Graph()\n","    network.add_nodes_from(range(len(self.agents)))\n","    return network\n","\n","  def draw_network(self):\n","    nx.draw(self.network, with_labels=True)\n","    plt.show()\n","\n","  def create_group(self, members: list[int], model: str):\n","    connections = list(combinations(members, 2))\n","    self.network.add_edges_from(connections)\n","\n","    members = [self.agents[member] for member in members]\n","    group = Group(members, model)\n","    self.groups.append(group)\n","\n","    return group"],"metadata":{"id":"9juJakV39-ep"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Group** Class  \n","Manages a group of agents, facilitates chat-based interactions, tracks message history, and supports AI-generated communication.\n","\n","**Attributes:**\n","\n","- `members`: List of `Agent` instances in the group.\n","- `model`: The language model used for generating responses.\n","- `chats`: List of chat records, each containing a sender, recipients, and a message.\n","\n","**Methods:**\n","\n","- `add_chat(member, message)`:  \n","  Adds a chat entry from the given agent to all other group members.\n","\n","- `get_members_details(indices)`:  \n","  Returns the `persona` dictionaries of specified members by their indices.\n","\n","- `get_list_messages(member)`:  \n","  Returns a list of messages sent by the specified agent.\n","\n","- `get_chats_history(last_n)`:  \n","  Returns the most recent `n` chat entries in a structured format (with sender, recipients, and message).\n","\n","- `send_message(sender_idx, prompt_start, len_chat_memory)`:  \n","  Constructs a conversation prompt using agent personas and chat history, sends it to the model, and retrieves a generated message. Rotates clients if a request fails.\n","\n","- `communicate(prompt_start, rounds, len_chat_memory)`:  \n","  Runs multi-round interaction where each agent sends a message per round. New messages are added to the chat log and printed after each exchange."],"metadata":{"id":"uErWX4Mm_Dkv"}},{"cell_type":"code","source":["class Group:\n","  def __init__(self, members: list[Agent], model: str):\n","    self.members = members\n","    self.model = model\n","    self.chats = [] # [{'sender': <Agent>, 'recipients': [<Agent>, ...], 'message': <str>}, ...]\n","\n","  def add_chat(self, member: Agent, message: str):\n","    recipients = [m for m in self.members if m != member]\n","    chat = {'sender': member, 'recipients': recipients, 'message': message}\n","    self.chats.append(chat)\n","\n","  def get_members_details(self, indices: list[int]):\n","    return [self.members[i].persona for i in indices]\n","\n","  def get_list_messages(self, member: Agent):\n","    return [chat['message'] for chat in self.chats if chat['sender'] == member]\n","\n","  def get_chats_history(self, last_n: int|None = None):\n","    num_all_chats = len(self.chats)\n","    last_n = num_all_chats if (last_n is None) else min(last_n, num_all_chats)\n","\n","    chats_history = [\n","        {\n","            'sender': chat['sender'].persona['Name'],\n","            'recipients': [recipient.persona['Name'] for recipient in chat['recipients']],\n","            'message': chat['message']\n","        } for chat in self.chats[-last_n:]\n","    ]\n","\n","    return chats_history\n","\n","  def send_message(self, sender_idx: int, prompt_start: str, len_chat_memory: int|None = None):\n","    sender_details = self.get_members_details([sender_idx])\n","\n","    receivers_indices = [j for j in range(len(self.members)) if j != sender_idx]\n","    receivers_details = self.get_members_details(receivers_indices)\n","\n","    prompt = f\"You are {sender_details}, engaging in a friendly conversation with: {receivers_details}.\\n\"\n","    prompt += f\"This is the chat history so far: {self.get_chats_history(len_chat_memory)}.\\n\"\n","    prompt += \"\"\"Generate only the next message in the conversation, using your natural personality and communication style. \\\n","    Assume this is an online chat on social media, not an in-person conversation. \\\n","    If the chat history is empty, begin the conversation yourself—do not simulate the other participant’s message.\\n\"\"\"\n","    prompt += prompt_start\n","\n","    def get_client_response():\n","      try:\n","        return current_client.chat.completions.create(\n","            model=self.model,\n","            messages=[\n","                {\n","                    'role': 'user',\n","                    'content': prompt\n","                }\n","            ],\n","        )\n","      except:\n","        return None\n","\n","    num_failed_tries = 0\n","    while True:\n","        response = get_client_response()\n","        if response is not None:\n","            break\n","        num_failed_tries += 1\n","        if num_failed_tries > len(clients):\n","            sys.exit('No response from any client')\n","        update_current_client()\n","\n","    return response.choices[0].message.content.strip()\n","\n","  def communicate(self, prompt_start: str, rounds: int, len_chat_memory: int|None = None):\n","    for _ in range(rounds):\n","      for sender_idx in range(len(self.members)):\n","        message = self.send_message(sender_idx, prompt_start, len_chat_memory)\n","        self.add_chat(self.members[sender_idx], message)\n","        pprint(self.get_chats_history(1))"],"metadata":{"id":"w6SMY7J6BPfP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. Experiments"],"metadata":{"id":"xd-XilJtCokj"}},{"cell_type":"markdown","source":["**Agent Initialization and Social Network Setup**  \n","Defines a set of agent personas and constructs a social network based on them.\n","\n","**Attributes:**\n","\n","- `persona_keys`: List of attributes used to define each agent.\n","- `personas`: A list of individual personas, each represented as a list of attribute values.\n","- `agents`: A list of `Agent` objects created by mapping `persona_keys` to each persona's values.\n","- `social_network`: An instance of the `SocialNetwork` class initialized with the generated agents.\n"],"metadata":{"id":"k6diORArHYwZ"}},{"cell_type":"code","source":["persona_keys = ['Name', 'Gender', 'Age', 'Economic Status', 'Occupation']\n","\n","personas = [\n","  ['Kayla', 'Female', 'Teen', 'Working Class', 'TikTok Influencer'],\n","  ['Morgan', 'Nonbinary', 'Adult', 'Upper-Middle', 'Corporate Lawyer'],\n","  ['Frank', 'Male', 'Elderly', 'Poor', 'Uber Driver'],\n","  ['Karen', 'Female', 'Middle-Aged', 'Middle Class', 'Politician (Controversial)'],\n","  ['Leo', 'Male', 'Young Adult', 'Lower Class', 'Activist (Environmental)']\n","]\n","\n","agents = [Agent(dict(zip(persona_keys, persona))) for persona in personas]\n","\n","social_network = SocialNetwork(agents)"],"metadata":{"id":"nifm3MQ2684i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Experiment Configuration**  \n","Specifies the model, group combinations, prompts, and communication settings for simulation.\n","\n","**Attributes:**\n","\n","- `model` (static): The selected language model used for agent communication.\n","- `groups_length` (static): Number of agents per group (used to form combinations).\n","- `groups` (dynamic): All possible combinations of agent indices of length `groups_length`.\n","- `prompts_start` (dynamic): List of initial prompts for each experimental scenario.\n","- `communication_rounds` (static): Number of communication rounds each group will go through.\n","- `communication_memory` (dynamic): List of memory settings; `None` allows access to full chat history, while `10` limits it to the most recent 10 messages."],"metadata":{"id":"w6onzNP8Gz_q"}},{"cell_type":"code","source":["model = models['DeepSeek-V3-0324']\n","\n","groups_length = 4\n","groups = list(map(list, combinations(range(len(personas)), groups_length)))\n","\n","prompts_start = [\n","    {\n","        'title': \"work_life_balance\",\n","        'prompt': \"The topic is work–life balance. Share how you handle stress from your job, and whether you believe in strict boundaries or letting work and personal life blend naturally.\"\n","    },\n","    {\n","        'title': \"failure_reflection\",\n","        'prompt': \"Describe a time you failed or faced a major setback. How did you cope with it emotionally or logically, and what did you take away from the experience?\"\n","    },\n","    {\n","        'title': \"content_type\",\n","        'prompt': \"What kind of content grabs your attention the most — real-world stories, fantasy, how-to guides, philosophical debates, or emotional journeys? Why?\"\n","    },\n","]\n","\n","communication_rounds = 20\n","communication_memory = [None, 10] # `None` means having access to all previous chats"],"metadata":{"id":"K8F7z0vCFe4Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Experiment Execution Loop**  \n","Runs communication experiments for each group, prompt, and memory configuration, and stores the resulting chat history.\n","\n","**Process:**\n","\n","- Iterates over all combinations of:\n","  - `group`: A subset of agent indices.\n","  - `prompt_start`: A dictionary containing a `title` and `prompt` for initializing the conversation.\n","  - `len_chat_memory`: The number of previous messages to include as context (can be limited or `None` for full history).\n","\n","**Workflow per Experiment:**\n","\n","1. **Naming**:  \n","   Generates a unique experiment name using the group members, prompt title, and memory length.\n","\n","2. **Group Creation**:  \n","   Uses `social_network.create_group()` to instantiate a group of agents for the current configuration.\n","\n","3. **Network Visualization**:  \n","   Calls `social_network.draw_network()` to display the current agent connections.\n","\n","4. **Communication Simulation**:  \n","   Starts the conversation using `group_obj.communicate()` with the given prompt and memory setting.\n","\n","5. **Result Saving**:  \n","   Stores the full chat history to a `.json` file named after the current experiment.\n","\n","**Note**:  \n","This setup allows scalable experimentation across various social setups and memory constraints."],"metadata":{"id":"B6MQyuSZRl6l"}},{"cell_type":"code","source":["for group in groups:\n","  for prompt_start in prompts_start:\n","    for len_chat_memory in communication_memory:\n","      experiment_name = f\"{group}-{prompt_start['title']}-{len_chat_memory}\"\n","\n","      group_obj = social_network.create_group(group, model)\n","\n","      social_network.draw_network()\n","\n","      group_obj.communicate(prompt_start['prompt'], communication_rounds, len_chat_memory)\n","\n","      with open(f\"{experiment_name}.json\", 'w') as f:\n","        json.dump(group_obj.get_chats_history(), f)"],"metadata":{"id":"Kq1CQhs9MXET"},"execution_count":null,"outputs":[]}]}